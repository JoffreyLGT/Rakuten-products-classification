{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version de Python utilisée : 3.9.xx\n",
    "# Import des librairies\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access to the raw dataset iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import data\n",
    "\n",
    "# Import des fichiers contenant les données\n",
    "df = data.load_data(\"data\").fillna(\"\")\n",
    "\n",
    "# data !!!!!\n",
    "features = df['designation']+\" \"+df['description']\n",
    "target = df['prdtypecode']\n",
    "\n",
    "# split to train, valid and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=123)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing & vectorisation pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Agnoli\\Datascientest\\Projet\\Fev23_BDS_Rakuten\\.conda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['etaient', 'etais', 'etait', 'etant', 'etante', 'etantes', 'etants', 'ete', 'etee', 'etees', 'etes', 'etiez', 'etions', 'eumes', 'eutes', 'fumes', 'fur', 'futes', 'konnen', 'konnte', 'meme', 'uber', 'wahrend', 'wurde', 'wurden'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from src.data.vectorization_pipeline import BagOfWordsDefault, TfidfV1\n",
    "from src.data.text_preproc_pipeline import TextPreprocess\n",
    "\n",
    "bow_preproc = TextPreprocess(TfidfV1())\n",
    "bow_preproc.fit(X_train)\n",
    "\n",
    "X_train_preproc = bow_preproc.transform(X_train)\n",
    "X_test_preproc = bow_preproc.transform(X_test)\n",
    "\n",
    "# bow_preproc.save(X_train_preproc, \"data/X_train_preproc\")\n",
    "# bow_preproc.save(X_test_preproc, \"data/X_test_preproc\")\n",
    "\n",
    "# bow_preproc.save(y_train, \"data/y_train\")\n",
    "# bow_preproc.save(y_test, \"data/y_test\")\n",
    "\n",
    "# print(bow_preproc.save_voc(\"data/voc\"))\n",
    "voc = bow_preproc.get_voc()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
